{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Mask RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import cv2\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training parameters.\n",
    "BATCH_SIZE  = 4\n",
    "IMG_SIZE    = [1024, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset sources.\n",
    "DATASET_IMGS = \"../../Data/Images\"\n",
    "DATASET_SEGM = \"../../Data/instance_segmentation\"\n",
    "LABELS_NAMES = \"../../Data/bounding_box\"\n",
    "\n",
    "DATASET_SEPA = \"../../Data/isolated_strawberrys\"\n",
    "DATASET_CROP = \"../../Data/isolated_strawberrys_cropped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset into variables.\n",
    "base_images = []\n",
    "segm_images = []\n",
    "\n",
    "# Get all the images within the path.\n",
    "for pth in os.listdir(DATASET_IMGS):\n",
    "\n",
    "    base_images.append(DATASET_IMGS + \"/\" + pth)\n",
    "    segm_images.append(DATASET_SEGM + \"/\" + pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance.\n",
    "def eucl_box(x1, y1, x2, y2):\n",
    "\n",
    "    dist_1 = np.sqrt(np.sum((np.array([x1, y1]) - np.array([x2, y2])) ** 2))\n",
    "\n",
    "    return dist_1\n",
    "\n",
    "def load_bounding_boxes(filename):\n",
    "\n",
    "    f = open(filename, \"r\")\n",
    "    lines = f.readlines()\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    for line in lines:\n",
    "\n",
    "        elements = line.split(' ')\n",
    "    \n",
    "        # Transform them.\n",
    "        id, cent_x, cent_y, width, height = elements\n",
    "        id = int(id)\n",
    "        cent_x, cent_y, width, height = [float(x) for x in [cent_x, cent_y, width, height]]\n",
    "\n",
    "        boxes.append([id, cent_x, cent_y, width, height])\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, segmentation in zip(base_images, segm_images):\n",
    "\n",
    "    # Load the image.\n",
    "    img = cv2.imread(image)\n",
    "    mask = cv2.imread(segmentation, 0)\n",
    "\n",
    "    # Get the masks.\n",
    "    masks_labels = [l for l in np.unique(mask) if l != 0]\n",
    "\n",
    "    # get the number ID and the height and width.\n",
    "    height, width = mask.shape\n",
    "    img_id = image.split('/')[-1].split('.')[-2]\n",
    "\n",
    "    # Iterate through the labels to get the masks.\n",
    "    for num, label_id in enumerate(masks_labels):\n",
    "\n",
    "        # Get that label as an isolated mask.\n",
    "        mask_i = (mask == label_id).astype(np.uint8)  # Read vesse instance mask\n",
    "\n",
    "        # Get the bounding box.\n",
    "        bb_coords = cv2.findNonZero(mask_i)\n",
    "        mask_bb_x, mask_bb_y, mask_bb_w, mask_bb_h = cv2.boundingRect(bb_coords)\n",
    "        bb_cent = (mask_bb_x + mask_bb_w / 2, mask_bb_y + mask_bb_h / 2)\n",
    "\n",
    "        min_distance = height * height\n",
    "        best_box = None\n",
    "        for box in load_bounding_boxes(LABELS_NAMES + '/' + img_id + '.txt'):\n",
    "\n",
    "            # Transform them into the good gormat.\n",
    "            box_id, box_cent_x, box_cent_y, box_width, box_height = box\n",
    "            box_cent_x *= width\n",
    "            box_cent_y *= height\n",
    "            box_width *= width\n",
    "            box_height *= height\n",
    "\n",
    "            dist = eucl_box(box_cent_x, box_cent_y, bb_cent[0], bb_cent[1])\n",
    "\n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "                best_box = (box_id, int(box_cent_x), int(box_cent_y))\n",
    "\n",
    "        # Display this image.\n",
    "        label = ['unripe', 'partially_ripe', 'fully_ripe'][best_box[0]]\n",
    "        label = str(best_box[0])\n",
    "        new_img = img * cv2.merge([mask_i, mask_i, mask_i])\n",
    "\n",
    "        new_filename = img_id + '-' + str(num) + '-' + label + '.png'\n",
    "\n",
    "        cv2.imwrite(DATASET_SEPA + '/' + new_filename, new_img)\n",
    "\n",
    "        # Crop the image.\n",
    "        crop_img = new_img[mask_bb_y:mask_bb_y + mask_bb_h, mask_bb_x:mask_bb_x + mask_bb_w]\n",
    "        \n",
    "        cv2.imwrite(DATASET_CROP + '/' + img_id + '_' + str(num) + '_' + label + '.png', crop_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
